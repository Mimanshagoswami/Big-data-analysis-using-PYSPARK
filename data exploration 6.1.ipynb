{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d8b56-cf9e-4d6a-af0e-d289d7084fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from pyspark.sql import SparkSession\\n\",\n",
    "    \"from pyspark.sql import functions as f\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from IPython.core.display import display\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"spark = SparkSession.builder.getOrCreate()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# General settings for display purposes\\n\",\n",
    "    \"pd.options.display.max_columns = None\\n\",\n",
    "    \"pd.options.display.max_rows = None\\n\",\n",
    "    \"pd.options.display.max_colwidth = 144\\n\",\n",
    "    \"sns.set(color_codes=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Source sentiment140: http://help.sentiment140.com/for-students/\\n\",\n",
    "    \"schema = \\\"polarity FLOAT, id LONG, date_time STRING, query STRING, user STRING, text STRING\\\"\\n\",\n",
    "    \"spark_reader = spark.read.schema(schema)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# file 1: testdata.manual.2009.06.14.csv\\n\",\n",
    "    \"TESTDATA_PATH = (\\n\",\n",
    "    \"    \\\"/home/jovyan/data-sets/sentiment-140-training-data/testdata.manual.2009.06.14.csv\\\"\\n\",\n",
    "    \")\\n\",\n",
    "    \"raw_test_data = spark_reader.csv(\\n\",\n",
    "    \"    TESTDATA_PATH,\\n\",\n",
    "    \"    quote='\\\"',\\n\",\n",
    "    \"    header=False,\\n\",\n",
    "    \"    inferSchema=True,\\n\",\n",
    "    \"    columnNameOfCorruptRecord=\\\"corrupt_data\\\",\\n\",\n",
    "    \").cache()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# file 2: training.1600000.processed.noemoticon.csv\\n\",\n",
    "    \"TRAININGDATA_PATH = \\\"/home/jovyan/data-sets/sentiment-140-training-data/training.1600000.processed.noemoticon.csv\\\"\\n\",\n",
    "    \"raw_training_data = spark_reader.csv(\\n\",\n",
    "    \"    TRAININGDATA_PATH,\\n\",\n",
    "    \"    quote='\\\"',\\n\",\n",
    "    \"    header=False,\\n\",\n",
    "    \"    inferSchema=True,\\n\",\n",
    "    \"    columnNameOfCorruptRecord=\\\"corrupt_data\\\",\\n\",\n",
    "    \").cache()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# path that we will write our raw data to\\n\",\n",
    "    \"OUTPUT_PATH = \\\"/home/jovyan/data-sets/sentiment-140-training-data/RAW\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# First look at the test data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Count of data\\n\",\n",
    "    \"print(f\\\"Overall data count: {raw_test_data.count()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Data summary\\n\",\n",
    "    \"display(raw_test_data.summary().toPandas())\\n\",\n",
    "    \"print(\\\"Data schema\\\")\\n\",\n",
    "    \"raw_test_data.printSchema()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Let's look at 50 rows of data\\n\",\n",
    "    \"display(raw_test_data.limit(50).toPandas())\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# First look at the training data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Count of data\\n\",\n",
    "    \"print(f\\\"Overall data count: {raw_training_data.count()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Data summary\\n\",\n",
    "    \"display(raw_training_data.summary().toPandas())\\n\",\n",
    "    \"print(\\\"Data schema\\\")\\n\",\n",
    "    \"raw_training_data.printSchema()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Let's look at 50 rows of data\\n\",\n",
    "    \"display(raw_training_data.limit(50).toPandas())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Test data:\\n\",\n",
    "    \"- 498 rows of test_data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Training data:\\n\",\n",
    "    \"- 1600000 rows of training_data\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Initial Findings:\\n\",\n",
    "    \"- We need to apply a proper schema\\n\",\n",
    "    \"- The date column needs fixing\\n\",\n",
    "    \"- We need to extract twitter user names/handles (we'll extract it and call the output column `users_mentioned`)\\n\",\n",
    "    \"- We need to extract hashtags and replace them with the words from the hashtag (we'll extract it and call the output column `hashtags`)\\n\",\n",
    "    \"- We need to extract URLs, as our algorithm won't need that or use that (we'll simply remove it from the data)\\n\",\n",
    "    \"- The same goes for email-address\\n\",\n",
    "    \"- HTML does not appear properly unescaped, we're going to have to fix that (example: `&lt;3` and `s&amp;^t`)\\n\",\n",
    "    \"- Encoding seems to be 'broken' (example: `�����ߧ�ǿ�����ж�؜��� &lt;&lt;----I DID NOT KNOW I CUD or HOW TO DO ALL DAT ON MY PHONE TIL NOW. WOW..MY LIFE IS NOW COMPLETE. JK.`)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Detailed statistics\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Polarity\\n\",\n",
    "    \"According to Sentiment140 documentation, we would expect the `polarity` column to have one of three values representing user sentiment:\\n\",\n",
    "    \"- 0 = negative\\n\",\n",
    "    \"- 2 = neutral\\n\",\n",
    "    \"- 4 = positive\\n\",\n",
    "    \"\\n\",\n",
    "    \"Once we train our own model, we don't want data-skew to introduce bias. So let's see how polarity is distributed in the data that we have.\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### Polarity column (test data)\\n\",\n",
    "    \"Let's first look at the test data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df = raw_test_data.select(\\\"polarity\\\").na.drop()\\n\",\n",
    "    \"print(f\\\"No of rows with Polarity: {df.count()}/{raw_test_data.count()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"sns.distplot(df.toPandas())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"#### Polarity column (training data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now let's look at the training data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df = raw_training_data.select(\\\"polarity\\\").na.drop()\\n\",\n",
    "    \"print(f\\\"No of rows with Polarity: {df.count()} / {raw_training_data.count()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"sns.distplot(df.toPandas())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"#### Results:\\n\",\n",
    "    \"We can clearly see that the training data only has polarity data centered around 0 (Negative) and 4 (Positive).\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's confirm this:\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"polarity_df = raw_training_data.select(\\\"polarity\\\").cache()\\n\",\n",
    "    \"\\n\",\n",
    "    \"polarity_df.groupBy(\\\"polarity\\\").count().toPandas()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Very nice! We have a nice even 50/50 split between polarity.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Conclusions:\\n\",\n",
    "    \"- As 498 rows is way too little for us to train a model on, we're going to disregard this dataset and focus on the Training Data. \\n\",\n",
    "    \"- We've determined the steps that need to be taken to clean the data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Store our raw data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now it's time for us to write the raw data we intend to use to disk.  \\n\",\n",
    "    \"We're going to:\\n\",\n",
    "    \"- keep the format CSV\\n\",\n",
    "    \"- partition the data by polarity, this will create 2 subfolders inside our output folder \\n\",\n",
    "    \"- repartition the data in 20 partitions: This will ensure that we have 20 smaller csv files per partition\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"raw_training_data.repartition(20).write.partitionBy(\\\"polarity\\\").csv(\\n\",\n",
    "    \"    OUTPUT_PATH, mode=\\\"overwrite\\\"\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.7.3\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a3ff5-3a3b-4f65-a13d-9388903e24bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecad3fd-4eb6-4715-9a74-51a12bdec9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b27ea-ae2e-473a-943d-fc7a2fd603bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef22a717-2eb9-4e96-90af-ff11eddc510a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2313c22-96c6-442f-8574-6af191b96d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f71fc70-3e9f-4892-9bfd-07160e978dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d066da2-3199-425b-8166-b19e53ac67d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bf425-c17f-4543-8e4c-ce0f52b5d136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df93a8b-359b-47b6-b37e-317f1044ab0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc7108-ae8b-42a4-9d3a-1906d9fa7a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2731d4a-662a-4dcb-977b-9b632bed64b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652eb82b-4f7c-47a3-a63a-333c7fa5d4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
